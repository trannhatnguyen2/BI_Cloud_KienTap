# [XÃ¢y Dá»±ng Giáº£i PhÃ¡p Business Intelligence TrÃªn Ná»n Táº£ng ÄÃ¡m MÃ¢y Microsoft Azure Káº¿t Há»£p ELT Äá»™ng](https://github.com/trannhatnguyen2/BI_Cloud_KienTap)

## Member of group

### **`BoKho`**

| student_id | class   | full_name        | role   |
| ---------- | ------- | ---------------- | ------ |
| K204061440 | K20406T | Tran Nhat Nguyen | Leader |
| K204061446 | K20406C | Man Dac Sang     | Member |

# ğŸ“• Table of contents

<!--ts-->

- ğŸ› ï¸ [Requirements](#ï¸-requirements)
- ğŸ§™â€â™‚ï¸ [Data Source](#-data-source)
- ğŸš€ [Solution](#-solution)
- ğŸŒŠ [Building Data Lake](#-building-data-lake)
- ğŸ§± [Building Data Warehouse](#-building-data-warehouse)
- ğŸ“Š [Result](#ï¸-result)
- ğŸ“‚ [Files](#-files)
<!--te-->

 <br />

# ğŸ› ï¸ Requirements

Many businesses are using multiple systems and data is distributed across multiple sources and formatted in different file types. This leads to difficulties in importing and storing data, and if there are discrepancies, it can lead to many negative consequences such as loss of consistency, unnecessary costs, and impact on the business decision-making process.

# ğŸ§™â€â™‚ï¸ Data Source

The data was obtained from Kaggle for experimentation. It was divided into three different sources:

<p align="center">
<img src="./img/DataSources.png" width=70% height=70%>

<p align="center">
    Data Sources
</p>

1. `Databases`: recording sales activities on an e-commerce platform in Brazil regarding orders.

<p align="center">
<img src="./img/ERD_model.png" width=75% height=75%>

<p align="center">
    ERD model
</p>

2. `Accounting Systems`: recording and managing customer payment information for orders.
3. `Web Services`: customer comments on products and services.

# ğŸš€ Solution

<p align="center">
<img src="./img/BI_Process.png" width=100% height=100%>

<p align="center">
    BI Solution
</p>

- Step 1: Identify data sources and file formats for each source.
- Step 2: Extract data into the `rawdata` zone using a Python script; perform dynamic ELT processes into the "curated" zone to store and upload necessary data for analysis to Azure SQL Server.
- Step 3: Perform ETL processes into the Data Warehouse using Data Factory.
- Step 4: Visualize data using Power BI.

# ğŸŒŠ Building Data Lake

## Container

The tool used to create data storage zones on the Azure platform is Blob Storage.

<p align="center">
<img src="./img/Container.png" width=60% height=60%>

<p align="center">
    Containers
</p>

### **rawdata**

An exact copy of the data from sources, organized in an orderly folder structure.

```bash
./RAWDATA
â”œâ”€â”€ .accounting_systems/ <- Accounting System Source
â”‚ â”œâ”€â”€ Payment_2018_01.csv
â”‚ â”œâ”€â”€ Payment_2018_02.csv
â”‚ â””â”€â”€ Payment_2018_03.csv
â”‚
â”œâ”€â”€ .databases/ <- Databases Source
â”‚ â”œâ”€â”€ Customer_2018_01.csv
â”‚ â”œâ”€â”€ Customer_2018_02.csv
â”‚ â”œâ”€â”€ Customer_2018_03.csv
â”‚ â”œâ”€â”€ Order_2018_01.csv
â”‚ â”œâ”€â”€ Order_2018_02.csv
â”‚ |â”€â”€ Order_2018_03.csv
| â”œâ”€â”€ OrderItem_2018_01.csv
â”‚ |â”€â”€ OrderItem_2018_02.csv
â”‚ â””â”€â”€ OrderItem_2018_03.csv
â”‚
â”œâ”€â”€ .web_services/ <- Web Services Source
â”‚ â”œâ”€â”€ Review_2018_01.zip
â”‚ â”œâ”€â”€ Review_2018_01.zip
â”‚ â””â”€â”€ Review_2018_01.zip
```

### **staging**

Used to extract all compressed files to prepare for importing data into the `curated` zone.

### **curated**

```bash
./CURATED
â”œâ”€â”€ .EXTERNAL/
â”‚ â”œâ”€â”€ .Review/
    â”œâ”€â”€ .2018/
        â”œâ”€â”€ .01/
            â””â”€â”€ Review_2018_01.json
        â”œâ”€â”€ .02/
            â””â”€â”€ Review_2018_02.json
        â”œâ”€â”€ .03/
            â””â”€â”€ Review_2018_03.json
â”‚
â”œâ”€â”€ .INTERNAL/
â”‚ â”œâ”€â”€ .Accounting/
    â”œâ”€â”€ .Payment/
        â”œâ”€â”€ .2018/
            â”œâ”€â”€ .01/
                â””â”€â”€ Payment_2018_01.csv
            â”œâ”€â”€ .02/
                â””â”€â”€ Payment_2018_02.csv
            â”œâ”€â”€ .03/
                â””â”€â”€ Payment_2018_03.csv
â”‚ â”œâ”€â”€ .Sales/
    â”œâ”€â”€ .Customer/
        â”œâ”€â”€ .2018/
            â”œâ”€â”€ .01/
                â””â”€â”€ Customer_2018_01.csv
            â”œâ”€â”€ .02/
                â””â”€â”€ Customer_2018_02.csv
            â”œâ”€â”€ .03/
                â””â”€â”€ Customer_2018_03.csv
    â”œâ”€â”€ .Order/
        â”œâ”€â”€ .2018/
            â”œâ”€â”€ .01/
                â””â”€â”€ Order_2018_01.csv
            â”œâ”€â”€ .02/
                â””â”€â”€ Order_2018_02.csv
            â”œâ”€â”€ .03/
                â””â”€â”€ Order_2018_03.csv
    â”œâ”€â”€ .OrderItem/
        â”œâ”€â”€ .2018/
            â”œâ”€â”€ .01/
                â””â”€â”€ OrderItemm_2018_01.csv
            â”œâ”€â”€ .02/
                â””â”€â”€ OrderItemm_2018_02.csv
            â”œâ”€â”€ .03/
                â””â”€â”€ OrderItemm_2018_03.csv
```

# ğŸ§± Building Data Warehouse
